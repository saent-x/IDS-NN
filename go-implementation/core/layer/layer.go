package layer

import (
	"github.com/samber/lo"
	"gonum.org/v1/gonum/mat"
	"math/rand"
)

type Layer struct {
	Weights *mat.Dense
	Biases  *mat.Dense

	Weights_Momentum *mat.Dense
	Biases_Momentum  *mat.Dense

	Weights_Cache *mat.Dense
	Biases_Cache  *mat.Dense

	Inputs    *mat.Dense
	D_Weights *mat.Dense
	D_Biases  *mat.Dense
	D_Inputs  *mat.Dense

	Weight_Regularizer_L1 float64
	Weight_Regularizer_L2 float64
	Biases_Regularizer_L1 float64
	Biases_Regularizer_L2 float64

	Output *mat.Dense
}

func CreateLayer(n_inputs int, n_neurons int, weight_regularizer_l1, weight_regularizer_l2, bias_regularizer_l1, bias_regularizer_l2 float64) *Layer {
	layer := new(Layer)

	layer.Biases = mat.NewDense(1, n_neurons, make([]float64, n_neurons))
	layer.Biases.Zero()
	layer.Weights = mat.NewDense(n_inputs, n_neurons, nil)

	layer.Weights.Apply(func(i, j int, v float64) float64 {
		return 0.01 * rand.NormFloat64()
	}, layer.Weights)

	layer.Weight_Regularizer_L1 = weight_regularizer_l1
	layer.Weight_Regularizer_L2 = weight_regularizer_l2

	layer.Biases_Regularizer_L1 = bias_regularizer_l1
	layer.Biases_Regularizer_L2 = bias_regularizer_l2

	return layer
}

func MockLayer(n_inputs int, n_neurons int) *Layer {
	layer := new(Layer)

	layer.Biases = mat.NewDense(1, n_neurons, make([]float64, n_neurons))
	layer.Biases.Zero()

	if n_inputs == 2 {
		layer.Weights = mat.NewDense(n_inputs, n_neurons, []float64{
			-0.01306527, 0.01658131, -0.00118164,
			-0.00680178, 0.00666383, -0.0046072,
		})
	} else {
		layer.Weights = mat.NewDense(n_inputs, n_neurons, []float64{
			-0.01334258, -0.01346717, 0.00693773,
			-0.00159573, -0.00133702, 0.01077744,
			-0.01126826, -0.00730678, -0.0038488,
		})
	}

	return layer
}

func MockLayer64(n_inputs int, n_neurons int, weight_regularizer_l1, weight_regularizer_l2, bias_regularizer_l1, bias_regularizer_l2 float64) *Layer {
	layer := new(Layer)

	layer.Biases = mat.NewDense(1, n_neurons, make([]float64, n_neurons))
	layer.Biases.Zero()

	if n_inputs == 2 {
		layer.Weights = mat.NewDense(n_inputs, n_neurons, []float64{-0.013065268285572529, 0.016581306234002113, -0.0011816404294222593, -0.006801782175898552, 0.006663830950856209, -0.00460719782859087, -0.013342584483325481, -0.013467174023389816, 0.006937731523066759, -0.0015957342693582177, -0.0013370156520977616, 0.010777437128126621, -0.011268258094787598, -0.007306776940822601, -0.0038487978745251894, 0.0009435158572159708, -0.00042171450331807137, -0.0028688719030469656, -0.0006162640056572855, -0.0010730527574196458, -0.0071960436180233955, -0.00812993012368679, 0.002745163394138217, -0.008909150958061218, -0.011573553085327148, -0.0031229224987328053, -0.0015766700962558389, 0.022567233070731163, -0.007047002669423819, 0.00943260733038187, 0.007471883203834295, -0.011889449320733547, 0.007732529658824205, -0.011838806793093681, -0.026591721922159195, 0.006063195411115885, -0.017558906227350235, 0.004509344696998596, -0.006840108893811703, 0.01659550704061985, 0.010685092769563198, -0.00453385803848505, -0.006878376007080078, -0.012140773236751556, -0.00440922612324357, -0.0028035547584295273, -0.00364693533629179, 0.0015670385910198092, 0.005785214714705944, 0.0034965446684509516, -0.007641439326107502, -0.014377914369106293, 0.01364531833678484, -0.006894491612911224, -0.0065229362808167934, -0.005211893003433943, -0.018430694937705994, -0.004779739771038294, -0.0047965580597519875, 0.006203582976013422, 0.006984570994973183, 3.770889088627882e-05, 0.00931848306208849, 0.003399649867787957, -0.00015682111552450806, 0.0016092817531898618, -0.0019065348897129297, -0.003948494791984558, -0.0026773354038596153, -0.011280112899839878, 0.0028044169303029776, -0.009931235574185848, 0.008416312746703625, -0.0024945857003331184, 0.0004949498106725514, 0.0049383677542209625, 0.006433144677430391, -0.01570623368024826, -0.0020690367091447115, 0.00880178902298212, -0.016981057822704315, 0.0038728045765310526, -0.0225556418299675, -0.010225067846477032, 0.0003863055317196995, -0.016567151993513107, -0.00985510740429163, -0.014718350023031235, 0.016481349244713783, 0.0016422774642705917, 0.005672902800142765, -0.0022267510648816824, -0.00353431748226285, -0.016164740547537804, -0.0029183735605329275, -0.0076149217784404755, 0.008579239249229431, 0.01141101773828268, 0.014665787108242512, 0.008525519631803036, -0.005986539181321859, -0.01115896925330162, 0.007666631601750851, 0.003562927944585681, -0.017685383558273315, 0.0035548179876059294, 0.008145198225975037, 0.0005892558838240802, -0.0018505366751924157, -0.008076484315097332, -0.014465346932411194, 0.008002979680895805, -0.003091144608333707, -0.0023346664384007454, 0.017327211797237396, 0.006845010910183191, 0.0037082498893141747, 0.001420617918483913, 0.015199948102235794, 0.017195893451571465, 0.009295050986111164, 0.005822245962917805, -0.02094602957367897, 0.001237219083122909, -0.0013010695111006498, 0.0009395322995260358, 0.009430460631847382, -0.02739677205681801})
	} else {
		layer.Weights = mat.NewDense(n_inputs, n_neurons, []float64{-0.005693120416253805, 0.002699043368920684, -0.004668455105274916, -0.014169060625135899, 0.008689634501934052, 0.0027687191031873226, -0.009711045771837234, 0.003148171817883849, 0.008215856738388538, 5.2926461648894474e-05, 0.008005647920072079, 0.0007826017681509256, -0.003952289931476116, -0.011594204232096672, -0.0008593076490797102, 0.0019429292296990752, 0.00875832699239254, -0.001151074655354023, 0.004574155900627375, -0.009646119549870491, -0.007826291024684906, -0.0011038929224014282, -0.010546284727752209, 0.008202478289604187, 0.004631303250789642, 0.0027909576892852783, 0.0033890409395098686, 0.02021043561398983, -0.0046886419877409935, -0.02201441302895546, 0.0019930019043385983, -0.0005060354014858603, -0.005175190512090921, -0.009788298048079014, -0.004391895141452551, 0.0018133842386305332, -0.005028166808187962, 0.02412453666329384, -0.009605043567717075, -0.007931172847747803, -0.02288619987666607, 0.0025148442946374416, -0.020164065062999725, -0.005394546315073967, -0.0027567052748054266, -0.007097279187291861, 0.01738872565329075, 0.009943943470716476, 0.01319136843085289, -0.008824188262224197, 0.011285940185189247, 0.00496000936254859, 0.007714059203863144, 0.010294388048350811, -0.009087632410228252, -0.004243175964802504, 0.008625959977507591, -0.026556190103292465, 0.01513328030705452, 0.005531320348381996, -0.0004570396267808974, 0.0022050763946026564, -0.010299351997673512, -0.003499433631077409, 0.011002843268215656, 0.012980219908058643, 0.026962239295244217, -0.0007392466650344431, -0.006585529074072838, -0.005142339505255222, -0.010180418379604816, -0.0007785474881529808, 0.0038273241370916367, -0.0003424227761570364, 0.010963467881083488, -0.0023421579971909523, -0.003474506316706538, -0.005812684539705515, -0.01632634550333023, -0.0156776774674654, -0.01179157942533493, 0.01301428023725748, 0.008952602744102478, 0.013749640434980392, -0.013322115875780582, -0.019686246290802956, -0.006600562948733568, 0.0017581894062459469, 0.004986902698874474, 0.010479722172021866, 0.0028427967336028814, 0.017426686361432076, -0.0022260567639023066, -0.009130791760981083, -0.01681218296289444, -0.008889713324606419, 0.0024211795534938574, -0.008887202478945255, 0.009367424994707108, 0.014123275876045227, -0.023695869371294975, 0.008640523068606853, -0.022396039217710495, 0.004014990758150816, 0.012248705141246319, 0.0006485610501840711, -0.01279689185321331, -0.005854311864823103, -0.002616454381495714, -0.0018224477535113692, -0.002028968185186386, -0.0010988278081640601, 0.002134800422936678, -0.012085736729204655, -0.0024201981723308563, 0.015182611532509327, -0.0038464542012661695, -0.004438360687345266, 0.010781973600387573, -0.02559184469282627, 0.011813785880804062, -0.006319037638604641, 0.0016392855904996395, 0.0009632135624997318, 0.009424680843949318, -0.0026759475003927946, -0.006780257448554039, 0.01297845784574747, -0.023641739040613174, 0.00020334181317593902, -0.013479254208505154, -0.007615733426064253, 0.020112566649913788, -0.0004459542687982321, 0.0019506969256326556, -0.01781562715768814, -0.007290446665138006, 0.001965573988854885, 0.003547576954588294, 0.0061688655987381935, 8.62789893290028e-05, 0.005270041525363922, 0.00453781895339489, -0.018297404050827026, 0.00037005721242167056, 0.0076790242455899715, 0.005898797884583473, -0.003638588124886155, -0.00805626530200243, -0.0111831184476614, -0.0013105401303619146, 0.011330798268318176, -0.019518041983246803, -0.006598917301744223, -0.011398023925721645, 0.007849575020372868, -0.005543095991015434, -0.0047063762322068214, -0.0021694956813007593, 0.004453932400792837, -0.0039238897152245045, -0.030461430549621582, 0.005433118902146816, 0.004390429239720106, -0.0021954101976007223, -0.010840365663170815, 0.0035178011748939753, 0.003792355302721262, -0.004700328689068556, -0.0021673147566616535, -0.009301564656198025, -0.0017858908977359533, -0.015504293143749237, 0.004173188004642725, -0.009443684481084347, 0.0023810314014554024, -0.014059629291296005, -0.005900576710700989, -0.001104893977753818, -0.016606997698545456, 0.0011514787329360843, -0.003791475435718894, -0.017423560842871666, -0.013032427988946438, 0.006051200442016125, 0.008955559693276882, -0.0013190864119678736, 0.004047618247568607, 0.002238435437902808, 0.0032962297555059195, 0.01285983994603157, -0.015069983899593353})
	}

	layer.Weight_Regularizer_L1 = weight_regularizer_l1
	layer.Weight_Regularizer_L2 = weight_regularizer_l2

	layer.Biases_Regularizer_L1 = bias_regularizer_l1
	layer.Biases_Regularizer_L2 = bias_regularizer_l2

	return layer
}

func MockLayer64_1000(n_inputs int, n_neurons int, weight_regularizer_l1, weight_regularizer_l2, bias_regularizer_l1, bias_regularizer_l2 float64) *Layer {
	layer := new(Layer)

	layer.Biases = mat.NewDense(1, n_neurons, make([]float64, n_neurons))
	layer.Biases.Zero()

	if n_inputs == 2 {
		layer.Weights = mat.NewDense(n_inputs, n_neurons, []float64{0.015932737, 0.005687224, -0.0011448704, 0.0025163025, -0.012108556, -0.003937337, 0.00085252576, 0.0009942198, -0.015306163, 0.0032762317, 0.002791965, -0.003770512, 4.174999e-05, -0.014834915, -0.014797956, 0.0013468725, -0.0066772318, -0.000115555194, 0.008394906, -0.0017392993, -0.02810668, -0.0015065364, -0.0048104404, -0.0023469436, 0.008997308, -0.015785301, 0.0024395662, 0.01570304, -0.006259431, 0.004723279, 0.0096630575, 0.0021023143, -0.0068509695, -0.00709521, 0.0074380017, 0.0059214905, -0.007864684, -0.011764731, -0.012808066, 0.016616518, -0.0006794512, 0.023602284, 0.005555456, 0.004395223, 0.0030627246, 0.009991499, -0.009660631, 0.021600131, -0.0010030171, -0.0070340005, 0.00302561, 0.010923389, -0.010075549, 0.0056686937, -0.007164441, -0.005062735, -0.0048948242, 0.0076354146, -0.011090727, 0.001926161, -0.0034341784, -0.008472102, -0.012135236, -0.012028883, -0.01633796, 0.008961672, -0.0024165316, 0.0015865193, 0.011781894, -0.012201172, -0.009415456, 0.0025471554, -0.018240795, -0.0057870853, -0.009248931, 0.0032952242, -0.0042581586, 0.020081494, 0.009378914, -0.008532384, -0.0038731343, -0.003475845, 0.033065744, -0.015101996, 0.0020353969, -0.020844322, -6.9374415e-05, 0.019098904, -0.004084554, 0.0110455435, -0.00066115224, -0.004224987, -0.0025165635, -0.005869026, -0.0062605827, -0.013301943, 0.015068008, -0.003930764, 0.002937743, -0.008765318, 0.011169906, -0.0027355577, -0.00091032666, -0.018289765, 0.003959762, 0.018115057, -0.008690775, -0.0045822915, -0.011383239, 0.0012916217, 0.00064024195, 0.007050811, 0.0055147354, -0.00812516, 0.0022494805, -0.003283011, -0.010910329, -0.0012685588, 0.038016602, 0.023151705, 0.001398266, 0.017388571, -0.00045383364, -0.0005313834, -0.019495716, -0.009601055, -0.007834992, 0.0010751903})
	} else {
		layer.Weights = mat.NewDense(n_inputs, n_neurons, []float64{0.00013984535, -0.0057894234, -0.005888132, -0.0016615313, -0.013814117, -0.006126385, -0.0038128986, -0.012489489, -0.0033023788, -0.008348071, 0.012353824, -0.002438038, -0.0018954566, 0.004280281, 0.0055696834, -0.017362418, -0.003767841, -0.009090323, -0.0014517024, -0.0053633256, 0.0015706946, -0.0098045925, -0.0056776726, -0.005911596, 0.010825914, 0.0036800366, 0.003688887, -0.0028631827, -0.0038471785, 0.0056100287, 0.007774339, 0.00015146784, 0.011416479, 0.01274155, -0.01664698, 0.0043037888, -0.00042601928, 0.0038828882, 0.0111597655, -0.009205381, -0.01620274, 0.011061915, -0.009984846, -0.006862195, 0.0020462088, -0.006861018, -0.015922107, 0.00034189768, -0.007814846, 0.0059785983, -0.0050607654, -0.0068844613, -0.0021000055, 0.010521535, 0.009079041, -0.010932262, 0.027997077, -0.0032577633, -0.011524158, 0.00888232, -0.0036167246, 0.021537194, 0.008474084, -0.0019871984, 0.015753068, 0.008491152, -0.012288951, 0.008883941, -0.0051648743, -0.00083326286, 0.0013105444, -0.008790961, -0.013333423, 0.00367784, -0.013882335, -0.025752027, -0.0083610555, 0.0033109242, -0.0026988112, 0.0126713095, 0.0018375348, -0.0076630968, -0.004395835, -0.014365413, 0.010857971, -0.013811001, -0.009204077, -0.0016028621, 2.3532644e-05, -0.015026503, -0.009055358, 0.002650406, 0.0112972325, 0.0034900354, -0.0002580976, -0.015624086, -0.0061734235, 0.0052149426, 0.010809466, 0.008893759, 0.0013807163, 0.012046005, 0.028814606, -0.0059386194, -0.007631158, 0.015184829, 0.0023546452, 0.0011230769, 0.0039237435, -0.0065448647, -0.010347953, -0.0077714752, 0.0124594625, -0.014366406, 0.004986546, -0.0055768746, -0.0035336688, 0.0074295094, 0.008439889, 0.0034297653, -0.018731197, 0.015709646, 0.013101965, 0.0009143683, 0.00010257817, 0.01801449, 0.009472243, -0.00029294402, -0.0029233866, -0.0019353711, 0.01177232, 0.010399917, -0.01613423, 0.0046464237, 0.008641213, -0.015064632, -2.9647512e-05, -0.017770436, 0.0012949284, -0.020832345, -0.006817455, -0.0061106593, -0.007088498, 0.014515281, 0.0053551053, -0.0039956886, -0.009330777, -0.002387763, -0.010291129, 0.009730799, 0.019967658, 0.010531998, 0.0033169033, -0.0016562877, -0.0040510627, 0.017452845, -0.005759356, 0.015610985, -0.011315392, -0.0029623166, -0.017140565, 0.0015923419, -0.012637276, 0.016650494, 0.0041227224, 0.0053739673, 0.0028267845, -0.010925408, 0.0012411829, 0.018370807, 8.554926e-05, -0.010170162, -0.018523425, -0.0071332697, -0.017622288, 0.008305173, 0.0078116725, -0.008756818, 0.006139813, -0.0057645463, -0.00045614282, 0.0037195554, -0.0044396, 0.0041820332, -0.01685728, 0.0011747498, -0.0003495202, -0.02046393, -0.018096901, -0.018595235, 0.004143068, 0.0012395962})
	}

	layer.Weight_Regularizer_L1 = weight_regularizer_l1
	layer.Weight_Regularizer_L2 = weight_regularizer_l2

	layer.Biases_Regularizer_L1 = bias_regularizer_l1
	layer.Biases_Regularizer_L2 = bias_regularizer_l2

	return layer
}

func (self *Layer) Forward(inputs *mat.Dense) {
	self.Inputs = inputs // set inputs to be used for backpropagation
	rows, _ := inputs.Dims()

	// calculate dot product between inputs and weights and store in output var.
	output := mat.NewDense(rows, self.Biases.RawMatrix().Cols, nil)
	output.Mul(inputs, self.Weights)

	// adds a bias to each row of the resulting dot product
	output.Apply(func(i, j int, value float64) float64 {
		return value + self.Biases.At(0, j)
	}, output)

	self.Output = output
}

func (self *Layer) Backward(d_values *mat.Dense) {
	_, c := d_values.Dims()
	inputs_T := self.Inputs.T()
	r0, _ := inputs_T.Dims()

	// Gradients on parameter - dot product between inputs and d_values
	self.D_Weights = mat.NewDense(r0, c, nil)
	self.D_Weights.Mul(inputs_T, d_values)

	// sum all cols in kd_values
	//col-wise and retain dims
	self.D_Biases = mat.NewDense(1, c, nil)
	lo.ForEach(lo.Range(c), func(item int, index int) {
		self.D_Biases.SetCol(index, []float64{mat.Sum(d_values.ColView(index))})
	})

	// ............

	if self.Weight_Regularizer_L1 > 0 {
		d_l1 := mat.DenseCopyOf(self.Weights)
		d_l1.Apply(func(i, j int, v float64) float64 {
			return lo.Ternary(v < 0, -1., 1.)
		}, self.Weights)

		var new_dweights mat.Dense
		new_dweights.Apply(func(i, j int, v float64) float64 {
			return self.Weight_Regularizer_L1 * v
		}, d_l1)

		self.D_Weights.Add(self.D_Weights, &new_dweights)
	}

	if self.Weight_Regularizer_L2 > 0 {
		var new_dweights mat.Dense
		new_dweights.Apply(func(i, j int, v float64) float64 {
			return (2 * self.Weight_Regularizer_L2) * v
		}, self.Weights)

		self.D_Weights.Add(self.D_Weights, &new_dweights)
	}

	if self.Biases_Regularizer_L1 > 0 {
		d_l1 := mat.DenseCopyOf(self.Biases)
		d_l1.Apply(func(i, j int, v float64) float64 {
			return lo.Ternary(v < 0, -1., 1.)
		}, self.Biases)

		var new_dbiases mat.Dense
		new_dbiases.Apply(func(i, j int, v float64) float64 {
			return self.Biases_Regularizer_L1 * v
		}, d_l1)

		self.D_Biases.Add(self.D_Biases, &new_dbiases)
	}

	if self.Biases_Regularizer_L2 > 0 {
		var new_dbiases mat.Dense
		new_dbiases.Apply(func(i, j int, v float64) float64 {
			return (2 * self.Biases_Regularizer_L2) * v
		}, self.Biases)

		self.D_Biases.Add(self.D_Biases, &new_dbiases)
	}

	// ............

	var result mat.Dense
	result.Mul(d_values, self.Weights.T())

	self.D_Inputs = mat.DenseCopyOf(&result)
}
