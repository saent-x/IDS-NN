package layer

import (
	"github.com/samber/lo"
	"gonum.org/v1/gonum/mat"
	"math/rand"
)

type Layer struct {
	Weights          *mat.Dense
	Biases           *mat.Dense
	Weights_Momentum *mat.Dense
	Biases_Momentum  *mat.Dense
	Weights_Cache    *mat.Dense
	Biases_Cache     *mat.Dense
	Inputs           *mat.Dense
	D_Weights        *mat.Dense
	D_Biases         *mat.Dense
	D_Inputs         *mat.Dense

	Output *mat.Dense
}

func CreateLayer(n_inputs int, n_neurons int) *Layer {
	layer := new(Layer)

	layer.Biases = mat.NewDense(1, n_neurons, make([]float64, n_neurons))
	layer.Biases.Zero()
	layer.Weights = mat.NewDense(n_inputs, n_neurons, nil)

	layer.Weights.Apply(func(i, j int, v float64) float64 {
		return 0.01 * rand.NormFloat64()
	}, layer.Weights)

	return layer
}

func MockLayer(n_inputs int, n_neurons int) *Layer {
	layer := new(Layer)

	layer.Biases = mat.NewDense(1, n_neurons, make([]float64, n_neurons))
	layer.Biases.Zero()

	if n_inputs == 2 {
		layer.Weights = mat.NewDense(n_inputs, n_neurons, []float64{
			-0.01306527, 0.01658131, -0.00118164,
			-0.00680178, 0.00666383, -0.0046072,
		})
	} else {
		layer.Weights = mat.NewDense(n_inputs, n_neurons, []float64{
			-0.01334258, -0.01346717, 0.00693773,
			-0.00159573, -0.00133702, 0.01077744,
			-0.01126826, -0.00730678, -0.0038488,
		})
	}

	return layer
}

func MockLayer64(n_inputs int, n_neurons int) *Layer {
	layer := new(Layer)

	layer.Biases = mat.NewDense(1, n_neurons, make([]float64, n_neurons))
	layer.Biases.Zero()

	if n_inputs == 2 {
		layer.Weights = mat.NewDense(n_inputs, n_neurons, []float64{-0.013065268285572529, 0.016581306234002113, -0.0011816404294222593, -0.006801782175898552, 0.006663830950856209, -0.00460719782859087, -0.013342584483325481, -0.013467174023389816, 0.006937731523066759, -0.0015957342693582177, -0.0013370156520977616, 0.010777437128126621, -0.011268258094787598, -0.007306776940822601, -0.0038487978745251894, 0.0009435158572159708, -0.00042171450331807137, -0.0028688719030469656, -0.0006162640056572855, -0.0010730527574196458, -0.0071960436180233955, -0.00812993012368679, 0.002745163394138217, -0.008909150958061218, -0.011573553085327148, -0.0031229224987328053, -0.0015766700962558389, 0.022567233070731163, -0.007047002669423819, 0.00943260733038187, 0.007471883203834295, -0.011889449320733547, 0.007732529658824205, -0.011838806793093681, -0.026591721922159195, 0.006063195411115885, -0.017558906227350235, 0.004509344696998596, -0.006840108893811703, 0.01659550704061985, 0.010685092769563198, -0.00453385803848505, -0.006878376007080078, -0.012140773236751556, -0.00440922612324357, -0.0028035547584295273, -0.00364693533629179, 0.0015670385910198092, 0.005785214714705944, 0.0034965446684509516, -0.007641439326107502, -0.014377914369106293, 0.01364531833678484, -0.006894491612911224, -0.0065229362808167934, -0.005211893003433943, -0.018430694937705994, -0.004779739771038294, -0.0047965580597519875, 0.006203582976013422, 0.006984570994973183, 3.770889088627882e-05, 0.00931848306208849, 0.003399649867787957, -0.00015682111552450806, 0.0016092817531898618, -0.0019065348897129297, -0.003948494791984558, -0.0026773354038596153, -0.011280112899839878, 0.0028044169303029776, -0.009931235574185848, 0.008416312746703625, -0.0024945857003331184, 0.0004949498106725514, 0.0049383677542209625, 0.006433144677430391, -0.01570623368024826, -0.0020690367091447115, 0.00880178902298212, -0.016981057822704315, 0.0038728045765310526, -0.0225556418299675, -0.010225067846477032, 0.0003863055317196995, -0.016567151993513107, -0.00985510740429163, -0.014718350023031235, 0.016481349244713783, 0.0016422774642705917, 0.005672902800142765, -0.0022267510648816824, -0.00353431748226285, -0.016164740547537804, -0.0029183735605329275, -0.0076149217784404755, 0.008579239249229431, 0.01141101773828268, 0.014665787108242512, 0.008525519631803036, -0.005986539181321859, -0.01115896925330162, 0.007666631601750851, 0.003562927944585681, -0.017685383558273315, 0.0035548179876059294, 0.008145198225975037, 0.0005892558838240802, -0.0018505366751924157, -0.008076484315097332, -0.014465346932411194, 0.008002979680895805, -0.003091144608333707, -0.0023346664384007454, 0.017327211797237396, 0.006845010910183191, 0.0037082498893141747, 0.001420617918483913, 0.015199948102235794, 0.017195893451571465, 0.009295050986111164, 0.005822245962917805, -0.02094602957367897, 0.001237219083122909, -0.0013010695111006498, 0.0009395322995260358, 0.009430460631847382, -0.02739677205681801})
	} else {
		layer.Weights = mat.NewDense(n_inputs, n_neurons, []float64{-0.005693120416253805, 0.002699043368920684, -0.004668455105274916, -0.014169060625135899, 0.008689634501934052, 0.0027687191031873226, -0.009711045771837234, 0.003148171817883849, 0.008215856738388538, 5.2926461648894474e-05, 0.008005647920072079, 0.0007826017681509256, -0.003952289931476116, -0.011594204232096672, -0.0008593076490797102, 0.0019429292296990752, 0.00875832699239254, -0.001151074655354023, 0.004574155900627375, -0.009646119549870491, -0.007826291024684906, -0.0011038929224014282, -0.010546284727752209, 0.008202478289604187, 0.004631303250789642, 0.0027909576892852783, 0.0033890409395098686, 0.02021043561398983, -0.0046886419877409935, -0.02201441302895546, 0.0019930019043385983, -0.0005060354014858603, -0.005175190512090921, -0.009788298048079014, -0.004391895141452551, 0.0018133842386305332, -0.005028166808187962, 0.02412453666329384, -0.009605043567717075, -0.007931172847747803, -0.02288619987666607, 0.0025148442946374416, -0.020164065062999725, -0.005394546315073967, -0.0027567052748054266, -0.007097279187291861, 0.01738872565329075, 0.009943943470716476, 0.01319136843085289, -0.008824188262224197, 0.011285940185189247, 0.00496000936254859, 0.007714059203863144, 0.010294388048350811, -0.009087632410228252, -0.004243175964802504, 0.008625959977507591, -0.026556190103292465, 0.01513328030705452, 0.005531320348381996, -0.0004570396267808974, 0.0022050763946026564, -0.010299351997673512, -0.003499433631077409, 0.011002843268215656, 0.012980219908058643, 0.026962239295244217, -0.0007392466650344431, -0.006585529074072838, -0.005142339505255222, -0.010180418379604816, -0.0007785474881529808, 0.0038273241370916367, -0.0003424227761570364, 0.010963467881083488, -0.0023421579971909523, -0.003474506316706538, -0.005812684539705515, -0.01632634550333023, -0.0156776774674654, -0.01179157942533493, 0.01301428023725748, 0.008952602744102478, 0.013749640434980392, -0.013322115875780582, -0.019686246290802956, -0.006600562948733568, 0.0017581894062459469, 0.004986902698874474, 0.010479722172021866, 0.0028427967336028814, 0.017426686361432076, -0.0022260567639023066, -0.009130791760981083, -0.01681218296289444, -0.008889713324606419, 0.0024211795534938574, -0.008887202478945255, 0.009367424994707108, 0.014123275876045227, -0.023695869371294975, 0.008640523068606853, -0.022396039217710495, 0.004014990758150816, 0.012248705141246319, 0.0006485610501840711, -0.01279689185321331, -0.005854311864823103, -0.002616454381495714, -0.0018224477535113692, -0.002028968185186386, -0.0010988278081640601, 0.002134800422936678, -0.012085736729204655, -0.0024201981723308563, 0.015182611532509327, -0.0038464542012661695, -0.004438360687345266, 0.010781973600387573, -0.02559184469282627, 0.011813785880804062, -0.006319037638604641, 0.0016392855904996395, 0.0009632135624997318, 0.009424680843949318, -0.0026759475003927946, -0.006780257448554039, 0.01297845784574747, -0.023641739040613174, 0.00020334181317593902, -0.013479254208505154, -0.007615733426064253, 0.020112566649913788, -0.0004459542687982321, 0.0019506969256326556, -0.01781562715768814, -0.007290446665138006, 0.001965573988854885, 0.003547576954588294, 0.0061688655987381935, 8.62789893290028e-05, 0.005270041525363922, 0.00453781895339489, -0.018297404050827026, 0.00037005721242167056, 0.0076790242455899715, 0.005898797884583473, -0.003638588124886155, -0.00805626530200243, -0.0111831184476614, -0.0013105401303619146, 0.011330798268318176, -0.019518041983246803, -0.006598917301744223, -0.011398023925721645, 0.007849575020372868, -0.005543095991015434, -0.0047063762322068214, -0.0021694956813007593, 0.004453932400792837, -0.0039238897152245045, -0.030461430549621582, 0.005433118902146816, 0.004390429239720106, -0.0021954101976007223, -0.010840365663170815, 0.0035178011748939753, 0.003792355302721262, -0.004700328689068556, -0.0021673147566616535, -0.009301564656198025, -0.0017858908977359533, -0.015504293143749237, 0.004173188004642725, -0.009443684481084347, 0.0023810314014554024, -0.014059629291296005, -0.005900576710700989, -0.001104893977753818, -0.016606997698545456, 0.0011514787329360843, -0.003791475435718894, -0.017423560842871666, -0.013032427988946438, 0.006051200442016125, 0.008955559693276882, -0.0013190864119678736, 0.004047618247568607, 0.002238435437902808, 0.0032962297555059195, 0.01285983994603157, -0.015069983899593353})
	}

	return layer
}

func (self *Layer) Forward(inputs *mat.Dense) {
	self.Inputs = inputs // set inputs to be used for backpropagation
	rows, _ := inputs.Dims()

	// calculate dot product between inputs and weights and store in output var.
	output := mat.NewDense(rows, self.Biases.RawMatrix().Cols, nil)
	output.Mul(inputs, self.Weights)

	// adds a bias to each row of the resulting dot product
	output.Apply(func(i, j int, value float64) float64 {
		return value + self.Biases.At(0, j)
	}, output)

	self.Output = output
}

func (self *Layer) Backward(d_values *mat.Dense) {
	_, c := d_values.Dims()
	inputs_T := self.Inputs.T()
	r0, _ := inputs_T.Dims()

	// Gradients on parameter - dot product between inputs and d_values
	self.D_Weights = mat.NewDense(r0, c, nil)
	self.D_Weights.Mul(inputs_T, d_values)

	// sum all cols in kd_values
	//col-wise and retain dims
	self.D_Biases = mat.NewDense(1, c, nil)
	lo.ForEach(lo.Range(c), func(item int, index int) {
		self.D_Biases.SetCol(index, []float64{mat.Sum(d_values.ColView(index))})
	})

	var result mat.Dense
	result.Mul(d_values, self.Weights.T())

	self.D_Inputs = mat.DenseCopyOf(&result)
}
